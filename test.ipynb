{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "test.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tmb7jdGM624"
      },
      "source": [
        "import os\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve('https://github.com/Nicholas-Kastanos/tf-yolov4-compress/archive/main.zip','tf-yolov4-compress.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ad3OLr0M625"
      },
      "source": [
        "%rm -r sample_data\n",
        "!unzip tf-yolov4-compress\n",
        "%cd tf-yolov4-compress-main/\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DItDS3h-PHky"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "print(\"Using TensorFlow version\", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98JqND7kVA2i"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDEgKSrJNhEj"
      },
      "source": [
        "# This wont run on Colab. There is not enough storage on the kernel\n",
        "!mkdir -p dataset/archives/\n",
        "!curl http://images.cocodataset.org/zips/train2017.zip --output dataset/archives/train2017.zip\n",
        "!curl http://images.cocodataset.org/zips/val2017.zip --output dataset/archives/val2017.zip\n",
        "!unzip dataset/archives/train2017.zip\n",
        "!unzip dataset/archives/val2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uc56iVpM626"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend, layers, optimizers, regularizers, callbacks\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import src.media as media\n",
        "import src.predict as predict\n",
        "import src.train as train\n",
        "import src.dataset as dataset\n",
        "\n",
        "from src.yolov4.yolov4 import YOLOv4"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-ByPHnIM626",
        "outputId": "293def72-e6c8-4411-ea3b-cfd35bd047de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(gpus)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwroGBKwM627"
      },
      "source": [
        "anchors = np.array([\n",
        "    [[12, 16], [19, 36], [40, 28]],\n",
        "    [[36, 75], [76, 55], [72, 146]],\n",
        "    [[142, 110], [192, 243], [459, 401]],\n",
        "]).astype(np.float32).reshape(3, 3, 2)\n",
        "strides = np.array([8, 16, 32])\n",
        "xyscales = np.array([1.2, 1.1, 1.05])\n",
        "input_size = (608, 416)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K27zeVDCM627"
      },
      "source": [
        "class_names_path = os.path.join(os.getcwd(), \"dataset\", \"coco.names\")\n",
        "classes = media.read_classes_names(class_names_path)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGYLNsuMM627"
      },
      "source": [
        "def load_dataset(\n",
        "    dataset_path,\n",
        "    dataset_type=\"converted_coco\",\n",
        "    label_smoothing=0.1,\n",
        "    image_path_prefix=None,\n",
        "    training=True,\n",
        "):\n",
        "    return dataset.Dataset(\n",
        "        anchors=anchors,\n",
        "        batch_size=batch_size,\n",
        "        dataset_path=dataset_path,\n",
        "        dataset_type=dataset_type,\n",
        "        data_augmentation=training,\n",
        "        input_size=input_size,\n",
        "        label_smoothing=label_smoothing,\n",
        "        num_classes=len(classes),\n",
        "        image_path_prefix=image_path_prefix,\n",
        "        strides=strides,\n",
        "        xyscales=xyscales,\n",
        "    )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USlqrDlbM628"
      },
      "source": [
        "train_data_set = load_dataset(\n",
        "    os.path.join(os.getcwd(), \"dataset\", \"train2017.txt\"),\n",
        "    image_path_prefix=os.path.join(os.getcwd(), 'dataset', 'archives', 'train2017.zip'),\n",
        "    label_smoothing=0.05\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luNsWuvjM628"
      },
      "source": [
        "val_data_set = load_dataset(\n",
        "    os.path.join(os.getcwd(), \"dataset\", \"val2017.txt\"),\n",
        "    image_path_prefix=os.path.join(os.getcwd(), 'dataset', 'archives', 'val2017.zip'),\n",
        "    label_smoothing=0.05\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhcYxmcBM628"
      },
      "source": [
        "epochs = 400\n",
        "batch_size = 32\n",
        "lr=1e-4\n",
        "def lr_scheduler(epoch):\n",
        "    if epoch < int(epochs * 0.5):\n",
        "        return lr\n",
        "    if epoch < int(epochs * 0.8):\n",
        "        return lr * 0.5\n",
        "    if epoch < int(epochs * 0.9):\n",
        "        return lr * 0.1\n",
        "    return lr * 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RfRpL3TM629"
      },
      "source": [
        "backend.clear_session()\n",
        "inputs = layers.Input([input_size[1], input_size[0], 3])\n",
        "yolo = YOLOv4(\n",
        "    anchors=anchors,\n",
        "    num_classes=len(classes),\n",
        "    xyscales=xyscales,\n",
        "    kernel_regularizer=regularizers.l2(0.0005)\n",
        ")\n",
        "model = keras.Sequential()\n",
        "model.add(inputs)\n",
        "model.add(yolo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ti59NmxM629"
      },
      "source": [
        "optimizer = optimizers.Adam(learning_rate=lr)\n",
        "loss_iou_type = \"ciou\"\n",
        "loss_verbose = 1\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=train.YOLOv4Loss(\n",
        "        batch_size=batch_size,\n",
        "        iou_type=loss_iou_type,\n",
        "        verbose=loss_verbose\n",
        "    )\n",
        ")\n",
        "\n",
        "verbose = 2\n",
        "callbacks = [\n",
        "    callbacks.LearningRateScheduler(lr_scheduler),\n",
        "    callbacks.TerminateOnNaN(),\n",
        "    callbacks.TensorBoard(\n",
        "        log_dir=os.path.join(os.getcwd(), \"logs\")\n",
        "    )\n",
        "]\n",
        "initial_epoch = 0\n",
        "steps_per_epoch = 100\n",
        "validation_steps = 50\n",
        "validation_freq = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4REo9M70M62-"
      },
      "source": [
        "model.fit(\n",
        "    train_data_set,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=verbose,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=val_data_set,\n",
        "    initial_epoch=initial_epoch,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        "    validation_freq=validation_freq\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}