{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tmb7jdGM624"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve('https://github.com/Nicholas-Kastanos/tf-yolov4-compress/archive/main.zip','tf-yolov4-compress.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ad3OLr0M625"
   },
   "outputs": [],
   "source": [
    "%rm -r sample_data\n",
    "!unzip tf-yolov4-compress\n",
    "%cd tf-yolov4-compress-main/\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DItDS3h-PHky"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "print(\"Using TensorFlow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98JqND7kVA2i"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDEgKSrJNhEj"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tensorboard\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from src.yolov4.yolov4 import YOLOv4\n",
    "import src.dataset as dataset\n",
    "import src.train as train\n",
    "import src.predict as predict\n",
    "import src.media as media\n",
    "import numpy as np\n",
    "from tensorflow_datasets.core.features import FeaturesDict, BBoxFeature\n",
    "from tensorflow_datasets.core.dataset_info import DatasetInfo\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import backend, layers, optimizers, regularizers, callbacks\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    data_dir = 'gs://tfds-data/datasets'\n",
    "else:\n",
    "    data_dir = os.path.join('/', 'media', 'nicholas', 'Data', 'nicho', 'Documents', 'tensorflow_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uc56iVpM626"
   },
   "outputs": [],
   "source": [
    "(ds_train, ds_val), ds_info = tfds.load(\n",
    "    'coco/2017',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    "    data_dir=data_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = np.array([\n",
    "    [[12, 16], [19, 36], [40, 28]],\n",
    "    [[36, 75], [76, 55], [72, 146]],\n",
    "    [[142, 110], [192, 243], [459, 401]],\n",
    "]).astype(np.float32).reshape(3, 3, 2)\n",
    "strides = np.array([8, 16, 32])\n",
    "xyscales = np.array([1.2, 1.1, 1.05])\n",
    "input_size = (416, 416)\n",
    "anchors_ratio = anchors / input_size[0]\n",
    "batch_size = 1\n",
    "grid_size = (input_size[1], input_size[0]) // np.stack(\n",
    "    (strides, strides), axis=1\n",
    ")\n",
    "label_smoothing = 0.1\n",
    "num_classes = ds_info.features[\"objects\"][\"label\"].num_classes\n",
    "class_dict = dict(\n",
    "    zip(\n",
    "        range(ds_info.features[\"objects\"][\"label\"].num_classes),\n",
    "        ds_info.features[\"objects\"][\"label\"].names\n",
    "    )\n",
    ")\n",
    "\n",
    "grid_xy = [\n",
    "    np.tile(\n",
    "        np.reshape(\n",
    "            np.stack(\n",
    "                np.meshgrid(\n",
    "                    (np.arange(_size[0]) + 0.5) / _size[0],\n",
    "                    (np.arange(_size[1]) + 0.5) / _size[1],\n",
    "                ),\n",
    "                axis=-1,\n",
    "            ),\n",
    "            (1, _size[0], _size[1], 1, 2),\n",
    "        ),\n",
    "        (1, 1, 1, 3, 1),\n",
    "    ).astype(np.float32)\n",
    "    for _size in grid_size  # (height, width)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-ByPHnIM626",
    "outputId": "293def72-e6c8-4411-ea3b-cfd35bd047de"
   },
   "outputs": [],
   "source": [
    "def bboxes_to_ground_truth(bboxes):\n",
    "    ground_truth = [\n",
    "        np.zeros(\n",
    "                (\n",
    "                    1,\n",
    "                    _size[0],\n",
    "                    _size[1],\n",
    "                    3,\n",
    "                    5 + num_classes,\n",
    "                ),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        for _size in grid_size\n",
    "    ]\n",
    "\n",
    "    for i, _grid in enumerate(grid_xy):\n",
    "        ground_truth[i][..., 0:2] = _grid\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        # [b_x, b_y, b_w, b_h, class_id]\n",
    "        xywh = np.array(bbox[:4], dtype=np.float32)\n",
    "        class_id = int(bbox[4])\n",
    "\n",
    "        # smooth_onehot = [0.xx, ... , 1-(0.xx*(n-1)), 0.xx, ...]\n",
    "        onehot = np.zeros(num_classes, dtype=np.float32)\n",
    "        onehot[class_id] = 1.0\n",
    "        uniform_distribution = np.full(\n",
    "            num_classes, 1.0 / num_classes, dtype=np.float32\n",
    "        )\n",
    "        smooth_onehot = (\n",
    "            1 - label_smoothing\n",
    "        ) * onehot + label_smoothing * uniform_distribution\n",
    "\n",
    "        ious = []\n",
    "        exist_positive = False\n",
    "        for i in range(len(grid_xy)):\n",
    "            # Dim(anchors, xywh)\n",
    "            anchors_xywh = np.zeros((3, 4), dtype=np.float32)\n",
    "            anchors_xywh[:, 0:2] = xywh[0:2]\n",
    "            anchors_xywh[:, 2:4] = anchors_ratio[i]\n",
    "            iou = train.bbox_iou(xywh, anchors_xywh)\n",
    "            ious.append(iou)\n",
    "            iou_mask = iou > 0.3\n",
    "\n",
    "            if np.any(iou_mask):\n",
    "                xy_grid = xywh[0:2] * (\n",
    "                    grid_size[i][1],\n",
    "                    grid_size[i][0],\n",
    "                )\n",
    "                xy_index = np.floor(xy_grid)\n",
    "\n",
    "                exist_positive = True\n",
    "                for j, mask in enumerate(iou_mask):\n",
    "                    if mask:\n",
    "                        _x, _y = int(xy_index[0]), int(xy_index[1])\n",
    "                        ground_truth[i][0, _y, _x, j, 0:4] = xywh\n",
    "                        ground_truth[i][0, _y, _x, j, 4:5] = 1.0\n",
    "                        ground_truth[i][0, _y, _x, j, 5:] = smooth_onehot\n",
    "\n",
    "        if not exist_positive:\n",
    "            index = np.argmax(np.array(ious))\n",
    "            i = index // 3\n",
    "            j = index % 3\n",
    "\n",
    "            xy_grid = xywh[0:2] * (\n",
    "                grid_size[i][1],\n",
    "                grid_size[i][0],\n",
    "            )\n",
    "            xy_index = np.floor(xy_grid)\n",
    "\n",
    "            _x, _y = int(xy_index[0]), int(xy_index[1])\n",
    "            ground_truth[i][0, _y, _x, j, 0:4] = xywh\n",
    "            ground_truth[i][0, _y, _x, j, 4:5] = 1.0\n",
    "            ground_truth[i][0, _y, _x, j, 5:] = smooth_onehot\n",
    "\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwroGBKwM627"
   },
   "outputs": [],
   "source": [
    "def resize_image(\n",
    "    image,\n",
    "    ground_truth\n",
    "):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    if width / height >= input_size[0] / input_size[1]:\n",
    "        scale = input_size[0] / width\n",
    "    else:\n",
    "        scale = input_size[1] / height\n",
    "\n",
    "    # Resize\n",
    "    if scale != 1:\n",
    "        width = int(round(width * scale))\n",
    "        height = int(round(height * scale))\n",
    "        padded_image = tf.image.resize_with_pad(\n",
    "            image, input_size[1], input_size[0])\n",
    "    else:\n",
    "        padded_image = np.copy(image)\n",
    "\n",
    "    # Resize ground truth\n",
    "    dw = input_size[0] - width\n",
    "    dh = input_size[1] - height\n",
    "\n",
    "    ground_truth = np.copy(ground_truth)\n",
    "\n",
    "    if dw > dh:\n",
    "        scale = width / input_size[0]\n",
    "        ground_truth[:, 0] = scale * (ground_truth[:, 0] - 0.5) + 0.5\n",
    "        ground_truth[:, 2] = scale * ground_truth[:, 2]\n",
    "    elif dw < dh:\n",
    "        scale = height / input_size[1]\n",
    "        ground_truth[:, 1] = scale * (ground_truth[:, 1] - 0.5) + 0.5\n",
    "        ground_truth[:, 3] = scale * ground_truth[:, 3]\n",
    "\n",
    "    return padded_image, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K27zeVDCM627"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def coco_to_yolo(features):\n",
    "    objects = features[\"objects\"]\n",
    "    bboxes: tf.Tensor = objects[\"bbox\"]\n",
    "    labels: tf.Tensor = objects[\"label\"]\n",
    "\n",
    "    x_center = tf.math.reduce_mean(\n",
    "        tf.concat(\n",
    "            [\n",
    "                tf.reshape(bboxes[:, 3], (tf.shape(bboxes)[0], 1)),\n",
    "                tf.reshape(bboxes[:, 1], (tf.shape(bboxes)[0], 1))\n",
    "            ],\n",
    "            axis=1\n",
    "        ),\n",
    "        axis=1,\n",
    "        keepdims=True\n",
    "    )\n",
    "    y_center = tf.math.reduce_mean(\n",
    "        tf.concat(\n",
    "            [\n",
    "                tf.reshape(bboxes[:, 2], (tf.shape(bboxes)[0], 1)),\n",
    "                tf.reshape(bboxes[:, 0], (tf.shape(bboxes)[0], 1))\n",
    "            ],\n",
    "            axis=1\n",
    "        ),\n",
    "        axis=1,\n",
    "        keepdims=True\n",
    "    )\n",
    "\n",
    "    width = tf.subtract(\n",
    "        tf.reshape(bboxes[:, 3], (tf.shape(bboxes)[0], 1)),\n",
    "        tf.reshape(bboxes[:, 1], (tf.shape(bboxes)[0], 1))\n",
    "    )\n",
    "\n",
    "    height = tf.subtract(\n",
    "        tf.reshape(bboxes[:, 2], (tf.shape(bboxes)[0], 1)),\n",
    "        tf.reshape(bboxes[:, 0], (tf.shape(bboxes)[0], 1))\n",
    "    )\n",
    "\n",
    "    labels = tf.reshape(labels, (tf.shape(labels)[0], 1))\n",
    "    position = tf.concat([x_center, y_center, width, height], axis=1)\n",
    "    modified_bboxes = tf.concat(\n",
    "        [position, tf.cast(labels, tf.float32)], axis=1)\n",
    "\n",
    "    image = features[\"image\"]\n",
    "    image, modified_bboxes = tf.numpy_function(\n",
    "        func=resize_image,\n",
    "        inp=[image, modified_bboxes],\n",
    "        Tout=[tf.float32, tf.float32]\n",
    "    )\n",
    "\n",
    "    ground_truth = tf.numpy_function(\n",
    "        func=bboxes_to_ground_truth,\n",
    "        inp=[modified_bboxes],\n",
    "        Tout=[tf.float32 for _size in grid_size]\n",
    "    )\n",
    "    \n",
    "    image.set_shape([input_size[0],input_size[1], 3])\n",
    "\n",
    "    ground_truth[0].set_shape((1, 52, 52, 3, 85))\n",
    "    ground_truth[1].set_shape((1, 26, 26, 3, 85))\n",
    "    ground_truth[2].set_shape((1, 13, 13, 3, 85))\n",
    "\n",
    "    return (image, (ground_truth[0], ground_truth[1], ground_truth[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example in ds_train.skip(5).take(1):\n",
    "\n",
    "#     mapped = coco_to_yolo(example)\n",
    "#     image = mapped[0]\n",
    "#     ground_truth = mapped[1]\n",
    "#     # for gt in ground_truth:\n",
    "#         # print(tf.shape(gt))\n",
    "#     # print(image.shape)\n",
    "#     # plt.imshow(image)\n",
    "#     # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGYLNsuMM627"
   },
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(\n",
    "    coco_to_yolo, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(1000)\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USlqrDlbM628"
   },
   "outputs": [],
   "source": [
    "ds_val = ds_val.map(\n",
    "    coco_to_yolo, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_val = ds_val.batch(batch_size)\n",
    "ds_val = ds_val.cache()\n",
    "ds_val = ds_val.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luNsWuvjM628"
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 1e-4\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    if epoch < int(epochs * 0.5):\n",
    "        return lr\n",
    "    if epoch < int(epochs * 0.8):\n",
    "        return lr * 0.5\n",
    "    if epoch < int(epochs * 0.9):\n",
    "        return lr * 0.1\n",
    "    return lr * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhcYxmcBM628"
   },
   "outputs": [],
   "source": [
    "backend.clear_session()\n",
    "inputs = layers.Input([input_size[0], input_size[1], 3])\n",
    "yolo = YOLOv4(\n",
    "    anchors=anchors,\n",
    "    num_classes=num_classes,\n",
    "    xyscales=xyscales,\n",
    "    kernel_regularizer=regularizers.l2(0.0005)\n",
    ")\n",
    "yolo(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RfRpL3TM629"
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=lr)\n",
    "loss_iou_type = \"ciou\"\n",
    "loss_verbose = 1\n",
    "\n",
    "yolo.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=train.YOLOv4Loss(\n",
    "        batch_size=batch_size,\n",
    "        iou_type=loss_iou_type,\n",
    "        verbose=loss_verbose\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Ti59NmxM629"
   },
   "outputs": [],
   "source": [
    "print(\"Tensorboard Version: \", tensorboard.__version__)\n",
    "\n",
    "logdir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "verbose = 2\n",
    "callbacks = [\n",
    "    callbacks.LearningRateScheduler(lr_scheduler),\n",
    "    callbacks.TerminateOnNaN(),\n",
    "    tensorboard_callback\n",
    "]\n",
    "initial_epoch = 0\n",
    "steps_per_epoch = 10  # 100\n",
    "validation_steps = 5  # 50\n",
    "validation_freq = 1  # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4REo9M70M62-"
   },
   "outputs": [],
   "source": [
    "yolo.fit(\n",
    "    ds_train,\n",
    "    epochs=epochs,\n",
    "    verbose=verbose,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=ds_val,\n",
    "    # initial_epoch=initial_epoch,\n",
    "    # steps_per_epoch=steps_per_epoch,\n",
    "    # validation_steps=validation_steps,\n",
    "    # validation_freq=validation_freq\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}